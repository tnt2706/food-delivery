import axios from 'axios';

import config from '../config/index.js';

const generateExpertPrompt = (userInput) => `
B·∫°n l√† m·ªôt chuy√™n gia h·ªó tr·ª£ kh√°ch h√†ng qua chatbot cho nh√† h√†ng H√†n Qu·ªëc **Kokoria** t·∫°i Vi·ªát Nam.  
H√£y tr·∫£ l·ªùi kh√°ch **b·∫±ng ti·∫øng Vi·ªát**, **ng·∫Øn g·ªçn (t·ªëi ƒëa 80 t·ª´)**, d·ªÖ hi·ªÉu, t·ª± nhi√™n, th√¢n thi·ªán v√† ƒë√∫ng th√¥ng tin.

---

üìå Th√¥ng tin v·ªÅ Kokoria:

- M√¥ h√¨nh: Nh√† h√†ng H√†n Qu·ªëc hi·ªán ƒë·∫°i, ph·ª•c v·ª• t·∫°i ch·ªó v√† giao h√†ng
- M√≥n ƒÉn ƒë·∫∑c tr∆∞ng:  
  ‚Ä¢ G√† r√°n H√†n Qu·ªëc üçó  
  ‚Ä¢ Tteokbokki üå∂Ô∏è  
  ‚Ä¢ Bibimbap ü•£  
  ‚Ä¢ M√¨ cay üçú  
  ‚Ä¢ M√≥n ƒÉn k√®m, tr√°ng mi·ªáng üç∞  
- Xem menu: https://kokoria.vercel.app  
- ƒê·∫∑t b√†n: https://kokoria.vercel.app/reservation  
- Chi nh√°nh:
  1. 207/33 ƒë∆∞·ªùng 3/2, Q.10  
  2. 573/2 S∆∞ V·∫°n H·∫°nh, Q.10  
  3. 106 L√™ VƒÉn Duy·ªát, Q. B√¨nh Th·∫°nh  
  4. 228A Tr·∫ßn H∆∞ng ƒê·∫°o, C·∫ßn Th∆°  
- Hotline: 070.879.6719  
- Facebook: https://facebook.com/kokoria.sg  
- Instagram: https://instagram.com/kokoria.sg  

---

üí¨ C√¢u h·ªèi t·ª´ kh√°ch:
"${userInput}"

---

üéØ Nhi·ªám v·ª• c·ªßa b·∫°n:
1. N·∫øu c√¢u h·ªèi li√™n quan ƒë·∫øn nh√† h√†ng (menu, m√≥n ƒÉn, chi nh√°nh, ƒë·∫∑t b√†n, li√™n h·ªá...), h√£y tr·∫£ l·ªùi ch√≠nh x√°c, ƒë√∫ng tr·ªçng t√¢m.
2. N·∫øu c√¢u h·ªèi **kh√¥ng li√™n quan ƒë·∫øn nh√† h√†ng Kokoria**, h√£y tr·∫£ l·ªùi **ng·∫Øn g·ªçn, l·ªãch s·ª±, ƒë√∫ng nghƒ©a** nh∆∞ m·ªôt AI t·ªïng qu√°t, tr√°nh ph·ªèng ƒëo√°n lan man. Lu√¥n gi·ªØ gi·ªçng ƒëi·ªáu th√¢n thi·ªán v√† t·ª± nhi√™n.

‚ö†Ô∏è Tr√°nh l·∫∑p l·∫°i c√¢u h·ªèi. Tr·∫£ l·ªùi g·ªçn, th√¢n thi·ªán, gi·ªëng ng∆∞·ªùi th·∫≠t h·ªó tr·ª£ kh√°ch.
`;


export const chatWithGPT = async (req, res) => {
  try {
    const { message } = req.query;
    const prompt = generateExpertPrompt(message);

    const apiUrl = 'https://api.openai.com/v1/chat/completions';

    const response = await axios.post(
      apiUrl,
      {
        model: 'gpt-4.1',
        messages: [{ role: 'user', content: prompt }],
        temperature: 0.7,
      },
      {
        headers: {
          Authorization: `Bearer ${config.openApiKey}`,
          'Content-Type': 'application/json',
        },
        timeout: 10000,
      }
    );

    const text = response?.data?.choices?.[0]?.message?.content;
    return res.json({ success: true, message: text });

  } catch (err) {
    console.error("L·ªói khi g·ªçi GPT API:", {
      message: err.message,
      status: err.response?.status,
      data: err.response?.data,
    });

    if (err.code === "ECONNABORTED") {
      return res.status(504).json({
        success: false,
        message: "‚è±Ô∏è H·ªá th·ªëng ƒëang qu√° t·∫£i, vui l√≤ng th·ª≠ l·∫°i sau v√†i ph√∫t.",
      });
    }

    return res.status(500).json({
      success: false,
      message: "‚ùå ƒê√£ x·∫£y ra l·ªói khi d√πng AI chat bot.",
    });
  }
};



export const chatWithGemini = async (req, res) => {
  try {
    const { message } = req.query;
    const prompt = generateExpertPrompt(message);

    const apiUrl =
      `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${config.geminiApiKey}`;

    const response = await axios.post(
      apiUrl,
      {
        contents: [{ parts: [{ text: prompt }] }],
      },
      {
        headers: { "Content-Type": "application/json" },
        timeout: 10000,
      }
    );

    const text = response?.data?.candidates?.[0]?.content?.parts?.[0]?.text;
    return res.json({ success: true, message: text });

  } catch (err) {
    console.error("L·ªói khi g·ªçi Gemini API:", {
      message: err.message,
      status: err.response?.status,
      data: err.response?.data,
    });

    if (err.code === "ECONNABORTED") {
      return res.status(504).json({
        success: false,
        message: "‚è±Ô∏è H·ªá th·ªëng ƒëang qu√° t·∫£i, vui l√≤ng th·ª≠ l·∫°i sau v√†i ph√∫t.",
      });
    }

    return res.status(500).json({
      success: false,
      message: "‚ùå ƒê√£ x·∫£y ra l·ªói khi d√πng AI chat bot.",
    });
  }
};

